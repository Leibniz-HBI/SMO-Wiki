# Datasets

Over the course of the build up of the SMO we present a growing collection of useful (social) media datasets. These will comprise Open Access Datasets and Access on Request Datasets, both collected by ourselves as well as collections by other projects.

***

## Open Access

### Datenbank öffentlicher Sprecher (DBÖS) / Database of Public Speakers (DOPS) [planned]

The [Leibniz Institute for Media Research](https://leibniz-hbi.de) works at the moment on a collection of public speakers as defined by pre-defined criterions, such as being member of a parliamentary body, press organisation, professional sports team, or another institution of public interest.

This collection will comprise general publicly available information about these public figures or entities, dependent on the category they fall in (e.g. journalists, politicians, celebrities) alongside with their public social media accounts.

We hope that it is possible to make this dataset open access and open it up to contributions on a data repository.

### Twitter Parliamentarian Database


### POLUSA Dataset


## Access on Request

We plan to make certain datasets available on request or in form of collaborations with the SMO. This is mostly necessary either due to ethical considerations, legal constraints or the Terms of Service of the APIs they have been collected with.

While we a working on a formal request procedure, please contact us [via email](mailto:smo@leibniz-hbi.de) if you are interested in one of the datasets in the meantime.

### German Twittersphere Core [available] (GETCORE)

This dataset comprises a sparsified sample of the German-speaking Twitter follow network. It was collected via an adaption of a graph sampling method that aims to prioritise the most central nodes in a network ([https://github.com/flxvctr/RADICES](https://github.com/flxvctr/RADICES)).

As a result it contains a set of approximately 200 000 accounts which makes up an estimated 40% of an average German-using Twitter account's followings (based on data from 2016 and 2019, we have reasons to assume however, that the user base is only changing slowly since 2016). A detailed description of the collection method and the dataset can be found in this journal paper: [https://journals.sagepub.com/doi/full/10.1177/2056305120984475](https://journals.sagepub.com/doi/full/10.1177/2056305120984475)

### useNews 

The useNews data set comes in (Puschmann & Haim, 2020). It combines three innovative data sources and links their content for the years 2018-2020: the Reuters Digital News Report (user preferences and rankings of news brands), MediaCloud (news content) and CrowdTangle (Facebook engagement metrics). The dataset can be found here: [https://osf.io/uzca3/](https://osf.io/uzca3/)

It comprises

* 3 million news items from 81 sources and 12 countries
* 530 million words
* 4 million Facebook posts from 400,000 Facebook users which mention these amounts.
* Overall, these posts received a cumulative
* 468 million likes,
* 216 million shares,
* 177 million comments.

### Mediacloud

[TODO]

***

## Roadmap for SMO provided datasets

Based on DOPS and GETCORE we plan to collect social media activity on all platforms that we will cover over the course of the next 4 years (i.e. Twitter, Online News Media, Youtube, Facebook, Instagram, and Wikipedia).

DOPS forms the basis of various social media trackings.

GETCORE provides an alternative to DOPS for the identification of relevant public speakers.

Based on both we will start continuous long-term collection of activity

* based on social media accounts of public actors (__ACTORS__)
* by media (__MEDIA__)

Additionally we will start a long-term collection by topics of interest (__TOPICS__) and short-term event-related tracking on a case by case or demand basis (__EVENTS__).

We plan to implement the collections in a half-year cycle, building up the collection platform by platform.

Most activity datasets will have to be accessible on request due to legal or ethical reasons.